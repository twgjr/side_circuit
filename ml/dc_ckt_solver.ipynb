{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import networkx as nx\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input Data for a Simple Circuit\n",
    "Circuit is an independent voltage source and a resistor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiDiGraph with 2 nodes and 2 edges\n",
      "(0, {'type': 'n', 'v': 0})\n",
      "(1, {'type': 'n', 'v': ''})\n",
      "(0, 1, {'type': 's', 'v': '', 'i': 1, 'p': ''})\n",
      "(1, 0, {'type': 'r', 'v': '', 'i': '', 'p': 2})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vr = nx.MultiDiGraph()\n",
    "vr.add_node(0,type='n',v=0)\n",
    "vr.add_node(1,type='n',v='')\n",
    "# tail of edge is starting node\n",
    "# head of edge is ending node\n",
    "vr.add_edges_from(\n",
    "        [\n",
    "            (0,1,{'type':'s','v':'','i':1,'p':''}),\n",
    "            (1,0,{'type':'r','v':'','i':'','p':2})\n",
    "        ]\n",
    "    )\n",
    "print(vr)\n",
    "for node in vr.nodes().data():\n",
    "    print(node)\n",
    "for edge in vr.edges.data():\n",
    "    print(edge)\n",
    "nx.draw(vr,with_labels = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Sizes of Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of element currents, voltages, and params = (2,1)\n",
      "size of node voltages = (2,1)\n"
     ]
    }
   ],
   "source": [
    "# create tensors for voltages, currents, and element params\n",
    "num_elements = vr.number_of_edges()\n",
    "num_nodes = vr.number_of_nodes()\n",
    "print(f'size of element currents, voltages, and params = ({num_elements},1)')\n",
    "print(f'size of node voltages = ({num_nodes},1)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Circuit Parameters for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(nx_list: list, params_order_map: dict, types_map: dict):\n",
    "    '''\n",
    "    input: node or edge list with data from nx graph. Key order is a list of maps \n",
    "    from the parameter key to the desired order in the ouput vectors [{str:int}]\n",
    "\n",
    "    output:  two matrices. \n",
    "                params matrix rows are each edge/node of graph.  Columns are\n",
    "                    each param value corresponding to key order\n",
    "                knowns matrix rows are each edge/node of graph.  Columns are \n",
    "                    boolean of if the param value is known\n",
    "    '''\n",
    "    param_matrix = []\n",
    "    knowns_matrix = []\n",
    "    type_matrix = []\n",
    "    num_params = len(next(iter(nx_list))[-1])-1\n",
    "    num_types = len(types_map)\n",
    "    print(f'len(key_order_map) = num_params => {len(params_order_map)}, {num_params}' )\n",
    "    assert(len(params_order_map) == num_params)\n",
    "    for item in nx_list: # each edge or node\n",
    "        last_element: dict = item[-1]\n",
    "        type_oh = [0]*(num_types) # one-hot encoding\n",
    "        values = [0]*(num_params)\n",
    "        knowns_oh = [0]*(num_params) # one-hot encoding\n",
    "        for parameter,value in last_element.items():\n",
    "            if(parameter == 'type'):\n",
    "                type_idx = types_map[value]\n",
    "                type_oh[type_idx] = 1\n",
    "                continue\n",
    "            \n",
    "            idx = params_order_map[parameter]\n",
    "            if(value==''):\n",
    "                values[idx] = 0.0\n",
    "                knowns_oh[idx] = 0\n",
    "            else:\n",
    "                values[idx] = float(value)\n",
    "                knowns_oh[idx] = 1\n",
    "        param_matrix.append(values)\n",
    "        knowns_matrix.append(knowns_oh)\n",
    "        type_matrix.append(type_oh)\n",
    "\n",
    "    param_matrix = np.array(param_matrix)\n",
    "    knowns_matrix = np.array(knowns_matrix)\n",
    "    type_matrix = np.array(type_matrix)\n",
    "        \n",
    "    return (type_matrix, param_matrix, knowns_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(key_order_map) = num_params => 1, 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0],\n",
       "        [1, 0, 0]]),\n",
       " array([[0.],\n",
       "        [0.]]),\n",
       " array([[1],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "node_param_order_map = {'v':0}\n",
    "types_map = {'n':0,'s':1, 'r':2}\n",
    "node_types, node_params, node_knowns = extract(vr.nodes().data(), node_param_order_map, types_map)\n",
    "node_types, node_params, node_knowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(key_order_map) = num_params => 3, 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 0],\n",
       "        [0, 0, 1]]),\n",
       " array([[0., 1., 0.],\n",
       "        [0., 0., 2.]]),\n",
       " array([[0, 1, 0],\n",
       "        [0, 0, 1]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_param_order_map = {'v':0, 'i':1, 'p':2}\n",
    "element_types, element_params, element_knowns = extract(vr.edges.data(), edge_param_order_map, types_map)\n",
    "element_types, element_params, element_knowns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indidence Matrix (KCL loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incidence matrix has rows representing nodes and columns representing edges.\n",
    "\n",
    "An edge starting and ending node is determined when the edge is created.\n",
    "Starting node is the \"tail\".  Ending node is the \"head\".  Visualize an arrow \n",
    "from starting node (tail) to ending node (head).\n",
    "\n",
    "Matrix entries represent the head and tail connections:\n",
    "\n",
    "* +1 = head\n",
    "* -1 = tail\n",
    "\n",
    "The solutions to the circuit will need to be transformed to make sense with\n",
    "respect to the original definition of heads and tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of incidence array = (2, 2)\n",
      "[[-1.  1.]\n",
      " [ 1. -1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\terry\\AppData\\Local\\Temp\\ipykernel_24508\\2172744076.py:2: FutureWarning: incidence_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  M_tensor = nx.incidence_matrix(G=vr,oriented=True)\n"
     ]
    }
   ],
   "source": [
    "# generate the incidence matrix and convert to numpy array, then pytorch tensor\n",
    "M_tensor = nx.incidence_matrix(G=vr,oriented=True)\n",
    "M_tensor = M_tensor.toarray()\n",
    "print(f'shape of incidence array = {M_tensor.shape}')\n",
    "print(M_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to create a modified incidence matrix for voltages.  Voltage sources have opposite polarity compared to other elements.  The polarity should go from tail (low potential) to head (high potential) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_map['s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_types[:,types_map['s']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [ True, False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_source_type_mask = np.zeros_like(M_tensor)\n",
    "v_source_type_mask += element_types[:,types_map['s']]\n",
    "v_source_type_mask = v_source_type_mask.astype(bool)\n",
    "v_source_type_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_tensor[v_source_type_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.],\n",
       "       [-1., -1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_tensor_voltage = M_tensor.copy()\n",
    "M_tensor_voltage[v_source_type_mask] *= -1\n",
    "M_tensor_voltage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KVL Matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use minimum spanning tree to find minimum number of voltage loops. Must cast the directional multigraph as undirectional due to missing MST algorithm in MultiDiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiEdgeDataView([(0, 1)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use spanning tree to \n",
    "vr_mst = nx.minimum_spanning_tree(nx.MultiGraph(vr))\n",
    "vr_mst.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutMultiEdgeDataView([])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = nx.difference(vr, vr_mst)\n",
    "missing_edges = R.edges()\n",
    "missing_edges"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all missing edges from MST from a copy of the directional multigraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OutMultiEdgeDataView([(0, 1), (1, 0)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vr.edges())\n",
    "vr_loops = copy.deepcopy(vr)\n",
    "vr_loops.remove_edges_from(missing_edges)\n",
    "vr_loops.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loops = []\n",
    "\n",
    "for missing_edge in missing_edges:\n",
    "    loop_graph = vr_loops.copy()\n",
    "    loop_graph.add_edges_from([missing_edge])\n",
    "    print(loop_graph.edges())\n",
    "    loops.append(loop_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop_graph.edges.data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Input Data to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_vector = node_params[:,0].reshape(num_nodes,1)\n",
    "v_vector = element_params[:,edge_param_order_map['v']].reshape(num_elements,1)\n",
    "i_vector = element_params[:,edge_param_order_map['i']].reshape(num_elements,1)\n",
    "param_vector = element_params[:,edge_param_order_map['p']].reshape(num_elements,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.],\n",
       "         [0.]], dtype=torch.float64),\n",
       " tensor([[0.],\n",
       "         [0.]], dtype=torch.float64),\n",
       " tensor([[1.],\n",
       "         [0.]], dtype=torch.float64),\n",
       " tensor([[0.],\n",
       "         [2.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pot_tensor = torch.tensor(pot_vector,requires_grad=False,dtype=torch.double,device=device)\n",
    "v_tensor = torch.tensor(v_vector,requires_grad=False,dtype=torch.double,device=device)\n",
    "i_tensor = torch.tensor(i_vector,requires_grad=False,dtype=torch.double,device=device)\n",
    "param_tensor = torch.tensor(param_vector,requires_grad=False,dtype=torch.double,device=device)\n",
    "pot_tensor,v_tensor,i_tensor,param_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ True],\n",
       "         [False]]),\n",
       " tensor([[False],\n",
       "         [False]]),\n",
       " tensor([[ True],\n",
       "         [False]]),\n",
       " tensor([[False],\n",
       "         [ True]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knowns masks\n",
    "pot_mask = node_knowns\n",
    "v_mask = element_knowns[:,edge_param_order_map['v']].reshape(num_elements,1)\n",
    "i_mask = element_knowns[:,edge_param_order_map['i']].reshape(num_elements,1)\n",
    "param_mask = element_knowns[:,edge_param_order_map['p']].reshape(num_elements,1)\n",
    "\n",
    "pot_mask = torch.tensor(pot_mask,dtype=bool, requires_grad=False,device=device)\n",
    "v_mask = torch.tensor(v_mask,dtype=bool,requires_grad=False,device=device)\n",
    "i_mask = torch.tensor(i_mask,dtype=bool,requires_grad=False,device=device)\n",
    "param_mask = torch.tensor(param_mask,dtype=bool,requires_grad=False,device=device)\n",
    "\n",
    "pot_mask, v_mask, i_mask, param_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False],\n",
       "         [ True]]),\n",
       " tensor([[True],\n",
       "         [True]]),\n",
       " tensor([[False],\n",
       "         [ True]]),\n",
       " tensor([[ True],\n",
       "         [False]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inverted knowns masks\n",
    "pot_mask_inv = ~pot_mask\n",
    "v_mask_inv = ~v_mask\n",
    "i_mask_inv = ~i_mask\n",
    "param_mask_inv = ~param_mask\n",
    "\n",
    "pot_mask_inv, v_mask_inv, i_mask_inv, param_mask_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_tensor[param_mask_inv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [ True]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resistor device equation\n",
    "resistor_mask = torch.tensor(element_types[:,types_map['r']],requires_grad=False,dtype=torch.bool,device=device)\n",
    "resistor_mask = resistor_mask.reshape(num_elements,1)\n",
    "resistor_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source device equation\n",
    "source_mask = torch.tensor(element_types[:,types_map['s']],requires_grad=False,dtype=torch.double,device=device)\n",
    "source_mask = source_mask.reshape(num_elements,1)\n",
    "source_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resistor_func = i_tensor * param_tensor - v_tensor\n",
    "resistor_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_resistor = resistor_func * resistor_mask\n",
    "masked_resistor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_tensor * param_tensor - v_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit Theory Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  1.],\n",
       "        [ 1., -1.]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_tensor = torch.tensor(M_tensor,requires_grad=True,dtype=torch.double,device=device)\n",
    "M_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.],\n",
       "        [-1., -1.]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_tensor_voltage = torch.tensor(M_tensor_voltage,requires_grad=True,dtype=torch.double,device=device)\n",
    "M_tensor_voltage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    " \n",
    "    def forward(self, input, max, min, eps = 1e-12):\n",
    "        ''' \n",
    "        normalize input tensor elementwise\n",
    "        '''\n",
    "        # x = input - mean\n",
    "        # x = x / (std + eps)\n",
    "        x = input / (max - min + eps)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KCL_error(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, M_tensor, i_tensor):\n",
    "        return M_tensor @ i_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KVL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, M_tensor, pot_tensor):\n",
    "        ''' \n",
    "        returns the voltage tensor that satisfies KVL using the matrix \n",
    "        multiplication of the incidence matrix (transposed) and the potentials\n",
    "        vector\n",
    "        eps is 'epsilon', a tiny constant to prevent divide by zero error\n",
    "        '''\n",
    "        return M_tensor.T @ pot_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KVL_error(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, M_tensor, pot_tensor, voltage_tensor):\n",
    "        ''' \n",
    "        returns the loss between voltage tensor calculated voltages via KVL\n",
    "        vector\n",
    "        '''\n",
    "        return M_tensor.T @ pot_tensor - voltage_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resistor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, i_tensor, v_tensor, param_tensor):\n",
    "        return i_tensor * param_tensor - v_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resistor_V(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, i_tensor, v_tensor, param_tensor):\n",
    "        return i_tensor * param_tensor - v_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resistor_I(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, v_tensor, i_tensor, param_tensor, eps = 1e-12):\n",
    "        return v_tensor / (param_tensor + eps) - i_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, a, a_mask, b, b_mask):\n",
    "        '''\n",
    "        a_mask is True when element in b is a known.\n",
    "        b_mask is True when element in b is relevant to a.\n",
    "        Add relevant elements from b to unknown elements in a\n",
    "        '''\n",
    "        # print(f'a = {a}')\n",
    "        # print(f'a_mask = {a_mask}')\n",
    "        # print(f'b = {b}')\n",
    "        # print(f'b_mask = {b_mask}')\n",
    "        a_mask_inv = ~a_mask\n",
    "        # print(f'a_mask_inv = {a_mask_inv}')\n",
    "        # only have b with non zero entries if relevant and fill unknowns in 'a'\n",
    "        b = b * a_mask_inv  # zero out spots in be to avoid adding to knowns in 'a'\n",
    "        b = b * b_mask # zero out the non-relevant fields 'b'\n",
    "        #zero out the mirror fields in 'a' to be added by 'b'\n",
    "        b_mask_inv = ~b_mask\n",
    "        # print(f'b_mask_inv = {b_mask_inv}')\n",
    "        a = a * b_mask_inv  # zero out relevant spots\n",
    "        a = a * a_mask # zero out the unknowns\n",
    "        return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Source(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward(self, v_tensor, param_tensor, source_mask):\n",
    "#         # zero out non-sources\n",
    "#         source_func = v_tensor - param_tensor\n",
    "#         masked_resistor = resistor_func * source_mask\n",
    "#         return masked_resistor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver(\n",
      "  (kcl_error): KCL_error()\n",
      "  (kvl): KVL()\n",
      "  (resistor): Resistor()\n",
      "  (norm): Normalize()\n",
      "  (resistor_v): Resistor_V()\n",
      "  (resistor_i): Resistor_I()\n",
      "  (combine): Combine()\n",
      "  (kvl_error): KVL_error()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class Solver(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # inputs with randomized unknowns\n",
    "        self.M = M_tensor # no unknowns\n",
    "        self.pot = nn.Parameter(pot_tensor + torch.rand_like(pot_tensor) * pot_mask_inv)\n",
    "        self.v = nn.Parameter(v_tensor + torch.rand_like(v_tensor) * v_mask_inv)\n",
    "        self.i = nn.Parameter(i_tensor + torch.rand_like(i_tensor) * i_mask_inv)\n",
    "        self.param = nn.Parameter(param_tensor + torch.rand_like(param_tensor) * param_mask_inv)\n",
    "\n",
    "        # declare custom modules\n",
    "        self.kcl_error = KCL_error()\n",
    "        self.kvl = KVL()\n",
    "        self.resistor = Resistor()\n",
    "        self.norm = Normalize()\n",
    "        self.resistor_v = Resistor_V()\n",
    "        self.resistor_i = Resistor_I()\n",
    "        self.combine = Combine()\n",
    "        self.kvl_error = KVL_error()\n",
    "\n",
    "    def forward(self): # no \"x\" or other inputs because no inference mode\n",
    "        # KVL loss\n",
    "        voltage_error = self.kvl_error(self.M, self.pot, self.v)\n",
    "                \n",
    "        # element equations mapping voltage -> current\n",
    "        element_error = self.resistor(  self.i[resistor_mask], \n",
    "                                        self.v[resistor_mask], \n",
    "                                        self.param[resistor_mask])\n",
    "\n",
    "        # KCL loss\n",
    "        current_error = self.kcl_error(self.M, self.i)\n",
    "\n",
    "        # return torch.cat(tensors=(current_error, voltage_error))\n",
    "        return current_error, voltage_error, element_error#element_error_i, element_error_v\n",
    "\n",
    "model = Solver().to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(),lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key to making it work consistently is separating the losses by equation that \n",
    "is being solved: kvl, kcl, elements, etc.  However, it struggles with large\n",
    "differences in values (1 vs 100 Ohms in the same circuit).  Needs some form of \n",
    "normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    for i in range(4):\n",
    "        # Compute prediction error\n",
    "        kcl_pred, kvl_pred, element_pred = model() # model takes no inputs\n",
    "        # kcl_pred, kvl_pred, element_pred_i, element_pred_v = model() # model takes no inputs\n",
    "        kcl_loss = loss_fn(kcl_pred, torch.zeros_like(kcl_pred))\n",
    "        kvl_loss = loss_fn(kvl_pred, torch.zeros_like(kvl_pred))\n",
    "        element_loss = loss_fn(element_pred, torch.zeros_like(element_pred))\n",
    "        # element_loss_i = loss_fn(element_pred_i, torch.zeros_like(element_pred_i))\n",
    "        # element_loss_v = loss_fn(element_pred_v, torch.zeros_like(element_pred_v))\n",
    "        \n",
    "        # zero out the cached set of gradients from previous backprop\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backpropagation to produce gradients\n",
    "        kcl_loss.backward()\n",
    "        kvl_loss.backward()\n",
    "        element_loss.backward()\n",
    "\n",
    "        # freeze parameters that are known circuit attributes before stepping optimizer\n",
    "        if(0 <= i < 1):\n",
    "            model.pot.grad = torch.zeros_like(model.pot.grad)\n",
    "        else:\n",
    "            model.pot.grad[pot_mask] = 0\n",
    "\n",
    "        if(1 <= i < 2):\n",
    "            model.v.grad = torch.zeros_like(model.v.grad)\n",
    "        else:\n",
    "            model.v.grad[v_mask] = 0\n",
    "\n",
    "        if(2 <= i < 3):\n",
    "            model.i.grad = torch.zeros_like(model.i.grad)\n",
    "        else:\n",
    "            model.i.grad[i_mask] = 0\n",
    "\n",
    "        if(3 <= i < 4):\n",
    "            model.param.grad = torch.zeros_like(model.param.grad)\n",
    "        else:\n",
    "            model.param.grad[param_mask] = 0\n",
    "        \n",
    "        # update the model parameters with gradients\n",
    "        optimizer.step()\n",
    "\n",
    "    return kcl_loss, kvl_loss, element_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No inference therefore no testing!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss = 0.701926325952714 (6.01926325952714 per unit change)\n",
      "epoch 53 loss = 4.12435672948054e-11 finished early for loss threshold\n",
      "Done!\n",
      "potentials = Parameter containing:\n",
      "tensor([[ 0.0000],\n",
      "        [-2.0000]], dtype=torch.float64, requires_grad=True)\n",
      "voltages = Parameter containing:\n",
      "tensor([[-2.0000],\n",
      "        [ 2.0000]], dtype=torch.float64, requires_grad=True)\n",
      "currents = Parameter containing:\n",
      "tensor([[1.0000],\n",
      "        [1.0000]], dtype=torch.float64, requires_grad=True)\n",
      "parameters = Parameter containing:\n",
      "tensor([[0.6319],\n",
      "        [2.0000]], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "total_loss = 0\n",
    "prev_loss = 0.1\n",
    "lt_prev_loss = 1000\n",
    "\n",
    "for t in range(epochs):\n",
    "    kcl_loss,kvl_loss,element_loss = train(model, loss_fn, optimizer)\n",
    "    max_loss = max(kcl_loss, kvl_loss, element_loss)\n",
    "    loss_change = abs(max_loss - prev_loss) / prev_loss\n",
    "    prev_loss = max_loss        \n",
    "\n",
    "    if (t % (epochs/10)) == 0:\n",
    "        print(f'epoch {t} loss = {max_loss} ({loss_change} per unit change)')\n",
    "        if max_loss > lt_prev_loss:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] /= 10\n",
    "            print(f'reducing learning rate')\n",
    "        lt_prev_loss = max_loss\n",
    "\n",
    "    if max_loss < 1e-10:\n",
    "        print(f'epoch {t} loss = {max_loss} finished early for loss threshold')\n",
    "        break\n",
    "\n",
    "print(\"Done!\")\n",
    "print(f'potentials = {model.pot}')\n",
    "print(f'voltages = {model.v}')\n",
    "print(f'currents = {model.i}')\n",
    "print(f'parameters = {model.param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3217f10b4e7366dd1a6cbf73464f125221bf8686d6dfc23b58c931b1c5e4bd4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
