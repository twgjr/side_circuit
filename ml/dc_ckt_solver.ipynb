{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import networkx as nx\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input Data for a Simple Circuit\n",
    "Circuit is an independent voltage source and a resistor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiDiGraph with 2 nodes and 2 edges\n",
      "(0, {'type': 'n', 'v': 0})\n",
      "(1, {'type': 'n', 'v': ''})\n",
      "(0, 1, {'type': 's', 'v': '', 'i': 1, 'p': ''})\n",
      "(1, 0, {'type': 'r', 'v': '', 'i': '', 'p': 1000})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vr = nx.MultiDiGraph()\n",
    "vr.add_node(0,type='n',v=0)\n",
    "vr.add_node(1,type='n',v='')\n",
    "# tail of edge is starting node\n",
    "# head of edge is ending node\n",
    "vr.add_edges_from(\n",
    "        [\n",
    "            (0,1,{'type':'s','v':'','i':1,'p':''}),\n",
    "            (1,0,{'type':'r','v':'','i':'','p':1000}),\n",
    "        ]\n",
    "    )\n",
    "print(vr)\n",
    "for node in vr.nodes().data():\n",
    "    print(node)\n",
    "for edge in vr.edges.data():\n",
    "    print(edge)\n",
    "nx.draw(vr,with_labels = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Sizes of Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of element currents, voltages, and attr = (2,1)\n",
      "size of node voltages = (2,1)\n"
     ]
    }
   ],
   "source": [
    "# create tensors for voltages, currents, and element attrs\n",
    "num_elements = vr.number_of_edges()\n",
    "num_nodes = vr.number_of_nodes()\n",
    "print(f'size of element currents, voltages, and attr = ({num_elements},1)')\n",
    "print(f'size of node voltages = ({num_nodes},1)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Circuit inputs for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(nx_list: list, attr_order_map: dict, types_map: dict):\n",
    "    '''\n",
    "    input: node or edge list with data from nx graph. Key order is a list of maps \n",
    "    from the attr key to the desired order in the ouput vectors [{str:int}]\n",
    "\n",
    "    output:  two matrices. \n",
    "                attr matrix rows are each edge/node of graph.  Columns are\n",
    "                    each attr value corresponding to key order\n",
    "                knowns matrix rows are each edge/node of graph.  Columns are \n",
    "                    boolean of if the attr value is known\n",
    "    '''\n",
    "    attr_matrix = []\n",
    "    knowns_matrix = []\n",
    "    type_matrix = []\n",
    "    num_attr = len(next(iter(nx_list))[-1])-1\n",
    "    num_types = len(types_map)\n",
    "    print(f'len(key_order_map) = num_attr => {len(attr_order_map)}, {num_attr}' )\n",
    "    assert(len(attr_order_map) == num_attr)\n",
    "    for item in nx_list: # each edge or node\n",
    "        last_element: dict = item[-1]\n",
    "        type_oh = [0]*(num_types) # one-hot encoding\n",
    "        values = [0]*num_attr\n",
    "        knowns_oh = [0]*num_attr # one-hot encoding\n",
    "        for attr,value in last_element.items():\n",
    "            if(attr == 'type'):\n",
    "                type_idx = types_map[value]\n",
    "                type_oh[type_idx] = 1\n",
    "                continue\n",
    "            \n",
    "            idx = attr_order_map[attr]\n",
    "            if(value==''):\n",
    "                values[idx] = 0.0\n",
    "                knowns_oh[idx] = 0\n",
    "            else:\n",
    "                values[idx] = float(value)\n",
    "                knowns_oh[idx] = 1\n",
    "        attr_matrix.append(values)\n",
    "        knowns_matrix.append(knowns_oh)\n",
    "        type_matrix.append(type_oh)\n",
    "\n",
    "    attr_matrix = np.array(attr_matrix)\n",
    "    knowns_matrix = np.array(knowns_matrix)\n",
    "    type_matrix = np.array(type_matrix)\n",
    "        \n",
    "    return (type_matrix, attr_matrix, knowns_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(key_order_map) = num_attr => 1, 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0],\n",
       "        [1, 0, 0]]),\n",
       " array([[0.],\n",
       "        [0.]]),\n",
       " array([[1],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "node_attr_order_map = {'v':0}\n",
    "types_map = {'n':0,'s':1, 'r':2}\n",
    "node_types, node_attr, node_knowns = extract(vr.nodes().data(), node_attr_order_map, types_map)\n",
    "node_types, node_attr, node_knowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(key_order_map) = num_attr => 3, 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 0],\n",
       "        [0, 0, 1]]),\n",
       " array([[   0.,    1.,    0.],\n",
       "        [   0.,    0., 1000.]]),\n",
       " array([[0, 1, 0],\n",
       "        [0, 0, 1]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr_order_map = {'v':0, 'i':1, 'p':2}\n",
    "element_types, element_attr, element_knowns = extract(vr.edges.data(), edge_attr_order_map, types_map)\n",
    "element_types, element_attr, element_knowns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indidence Matrix (KCL loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incidence matrix has rows representing nodes and columns representing edges.\n",
    "\n",
    "An edge starting and ending node is determined when the edge is created.\n",
    "Starting node is the \"tail\".  Ending node is the \"head\".  Visualize an arrow \n",
    "from starting node (tail) to ending node (head).\n",
    "\n",
    "Matrix entries represent the head and tail connections:\n",
    "\n",
    "* +1 = head\n",
    "* -1 = tail\n",
    "\n",
    "The solutions to the circuit will need to be transformed to make sense with\n",
    "respect to the original definition of heads and tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of incidence array = (2, 2)\n",
      "[[-1.  1.]\n",
      " [ 1. -1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\terry\\AppData\\Local\\Temp\\ipykernel_7188\\2172744076.py:2: FutureWarning: incidence_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  M_tensor = nx.incidence_matrix(G=vr,oriented=True)\n"
     ]
    }
   ],
   "source": [
    "# generate the incidence matrix and convert to numpy array, then pytorch tensor\n",
    "M_tensor = nx.incidence_matrix(G=vr,oriented=True)\n",
    "M_tensor = M_tensor.toarray()\n",
    "print(f'shape of incidence array = {M_tensor.shape}')\n",
    "print(M_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Input Data to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_vector = node_attr[:,0].reshape(num_nodes,1)\n",
    "v_vector = element_attr[:,edge_attr_order_map['v']].reshape(num_elements,1)\n",
    "i_vector = element_attr[:,edge_attr_order_map['i']].reshape(num_elements,1)\n",
    "attr_vector = element_attr[:,edge_attr_order_map['p']].reshape(num_elements,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.],\n",
       "         [0.]], dtype=torch.float64),\n",
       " tensor([[0.],\n",
       "         [0.]], dtype=torch.float64),\n",
       " tensor([[1.],\n",
       "         [0.]], dtype=torch.float64),\n",
       " tensor([[   0.],\n",
       "         [1000.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pot_tensor = torch.tensor(pot_vector,requires_grad=False,dtype=torch.double,device=device)\n",
    "v_tensor = torch.tensor(v_vector,requires_grad=False,dtype=torch.double,device=device)\n",
    "i_tensor = torch.tensor(i_vector,requires_grad=False,dtype=torch.double,device=device)\n",
    "attr_tensor = torch.tensor(attr_vector,requires_grad=False,dtype=torch.double,device=device)\n",
    "states = {}\n",
    "states['pot'] = pot_tensor\n",
    "states['v'] = v_tensor\n",
    "states['i'] = i_tensor\n",
    "states['attr'] = attr_tensor\n",
    "states['pot'],states['v'],states['i'],states['attr']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ True],\n",
       "         [False]]),\n",
       " tensor([[False],\n",
       "         [False]]),\n",
       " tensor([[ True],\n",
       "         [False]]),\n",
       " tensor([[False],\n",
       "         [ True]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knowns masks\n",
    "pot_mask = node_knowns\n",
    "v_mask = element_knowns[:,edge_attr_order_map['v']].reshape(num_elements,1)\n",
    "i_mask = element_knowns[:,edge_attr_order_map['i']].reshape(num_elements,1)\n",
    "attr_mask = element_knowns[:,edge_attr_order_map['p']].reshape(num_elements,1)\n",
    "\n",
    "pot_mask = torch.tensor(pot_mask,dtype=bool, requires_grad=False,device=device)\n",
    "v_mask = torch.tensor(v_mask,dtype=bool,requires_grad=False,device=device)\n",
    "i_mask = torch.tensor(i_mask,dtype=bool,requires_grad=False,device=device)\n",
    "attr_mask = torch.tensor(attr_mask,dtype=bool,requires_grad=False,device=device)\n",
    "\n",
    "pot_mask, v_mask, i_mask, attr_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False],\n",
       "         [ True]]),\n",
       " tensor([[True],\n",
       "         [True]]),\n",
       " tensor([[False],\n",
       "         [ True]]),\n",
       " tensor([[ True],\n",
       "         [False]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inverted knowns masks\n",
    "pot_mask_inv = ~pot_mask\n",
    "v_mask_inv = ~v_mask\n",
    "i_mask_inv = ~i_mask\n",
    "attr_mask_inv = ~attr_mask\n",
    "\n",
    "pot_mask_inv, v_mask_inv, i_mask_inv, attr_mask_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [ True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resistor device equation\n",
    "resistor_mask = torch.tensor(element_types[:,types_map['r']],requires_grad=False,dtype=torch.bool,device=device)\n",
    "resistor_mask = resistor_mask.reshape(num_elements,1)\n",
    "resistor_mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit Theory Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  1.],\n",
       "        [ 1., -1.]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_tensor = torch.tensor(M_tensor,requires_grad=True,dtype=torch.double,device=device)\n",
    "M_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base(input_tensor):\n",
    "    std_val = torch.std(input_tensor)\n",
    "    if(std_val > 0):\n",
    "        return std_val\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_tensor, base):\n",
    "    assert(base > 0)\n",
    "    return input_tensor / base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(input_tensor, base):\n",
    "    return input_tensor * base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KCL(nn.Module):\n",
    "    def __init__(self, M_init, i_init, i_mask):\n",
    "        super().__init__()\n",
    "        # inputs with randomized unknowns\n",
    "        self.M = M_init # no unknowns\n",
    "        self.i, self.i_base = i_init\n",
    "        self.register_parameter('i',self.i)\n",
    "        self.i_mask = i_mask\n",
    "\n",
    "    def forward(self):\n",
    "        current_error = self.M @ self.i\n",
    "        return current_error\n",
    "\n",
    "    def zero_known_grads(self):\n",
    "        self.i.grad[self.i_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KVL(nn.Module):\n",
    "    def __init__(self, M_init, pot_init, v_init, v_mask, pot_mask):\n",
    "        super().__init__()\n",
    "        # inputs with randomized unknowns\n",
    "        self.M = M_init # no unknowns\n",
    "        self.pot, self.pot_base = pot_init\n",
    "        self.register_parameter('pot',self.pot)\n",
    "        self.v, self.v_base = v_init\n",
    "        self.register_parameter('v',self.v)\n",
    "        self.v_mask = v_mask\n",
    "        self.pot_mask = pot_mask\n",
    "\n",
    "    def forward(self):\n",
    "        ''' \n",
    "        returns the loss between voltage tensor calculated voltages via KVL\n",
    "        vector\n",
    "        '''\n",
    "        kvl_error = self.M.T @ self.pot - self.v\n",
    "        return kvl_error\n",
    "\n",
    "    def zero_known_grads(self):\n",
    "        self.v.grad[self.v_mask] = 0\n",
    "        self.pot.grad[self.pot_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resistor(nn.Module):\n",
    "    def __init__(self, v_init, i_init, attr_init, v_mask, i_mask, attr_mask):\n",
    "        super().__init__()\n",
    "        # inputs with randomized unknowns\n",
    "        self.v, self.v_base = v_init\n",
    "        self.register_parameter('v',self.v)\n",
    "        self.i, self.i_base = i_init\n",
    "        self.register_parameter('i',self.i)\n",
    "        self.attr, self.attr_base = attr_init\n",
    "        self.register_parameter('attr',self.attr)\n",
    "        self.v_mask = v_mask\n",
    "        self.i_mask = i_mask\n",
    "        self.attr_mask = attr_mask\n",
    "\n",
    "    def forward(self):\n",
    "        resistor_v_error = self.i * self.attr - self.v\n",
    "        return resistor_v_error\n",
    "            \n",
    "    def zero_known_grads(self):\n",
    "        self.v.grad[self.v_mask] = 0\n",
    "        self.i.grad[self.i_mask] = 0\n",
    "        self.attr.grad[self.attr_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver():\n",
    "    ''' \n",
    "    Manages the training and interactions between models\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Shared Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param(input_tensor, tensor_mask, base):\n",
    "    with torch.no_grad():\n",
    "        # initialize random parameter tensor same size as input tensor\n",
    "        param_init = nn.Parameter(torch.ones_like(input_tensor))\n",
    "\n",
    "        # zero knowns positions\n",
    "        param_init[tensor_mask] = 0\n",
    "\n",
    "        # normalize only the knowns\n",
    "        knowns_norm = normalize(input_tensor, base)\n",
    "\n",
    "        # replace the normalized knowns in the init param tensor\n",
    "        param_init[tensor_mask] = input_tensor[tensor_mask] #FIXME later to use normalization\n",
    "\n",
    "    return param_init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters are always normalized.  Parameters are initialized with normalized values.  During training, the parameters are periodically renormalized from outside the model instance.  The final result will need to be recovered from the normalized model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_base = base(states['pot'])\n",
    "v_base = base(states['v'])\n",
    "i_base = base(states['i'])\n",
    "attr_base = v_base / i_base\n",
    "\n",
    "pot_init_tensor = init_param(states['pot'], pot_mask, pot_base)\n",
    "v_init_tensor = init_param(states['v'], v_mask, v_base)\n",
    "i_init_tensor = init_param(states['i'], i_mask,i_base)\n",
    "attr_init_tensor = init_param(states['attr'], attr_mask, attr_base)\n",
    "\n",
    "pot_param = (pot_init_tensor, pot_base)\n",
    "v_param = (v_init_tensor, v_base)\n",
    "i_param = (i_init_tensor, i_base)\n",
    "attr_param = (attr_init_tensor, attr_base)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Instance of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcl_model = KCL( M_init = M_tensor, \n",
    "                i_init = i_param,\n",
    "                i_mask=i_mask).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kvl_model = KVL( M_init = M_tensor, \n",
    "                pot_init = pot_param, \n",
    "                v_init = v_param,\n",
    "                v_mask = v_mask,\n",
    "                pot_mask=pot_mask).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = Resistor( v_init = v_param, \n",
    "                i_init = i_param, \n",
    "                attr_init = attr_param,\n",
    "                v_mask = v_mask,\n",
    "                i_mask = i_mask,\n",
    "                attr_mask = attr_mask\n",
    "                ).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcl_opt = torch.optim.Adam(params=kcl_model.parameters(),lr=0.9)\n",
    "kvl_opt = torch.optim.Adam(params=kvl_model.parameters(),lr=0.9)\n",
    "res_opt = torch.optim.Adam(params=res_model.parameters(),lr=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is multitask learning since there are multiple losses accessing common, hard parameters.  By separating the losses, Adam optimizer can use different learning rates of different parameter groups.  Each loss is associated with a key equation for solving circuits (e.g. KCL).  There are three ways to backpropagate the losses.  \n",
    "\n",
    "First is the common way.  Calculate all losses, sum them, then backpropogate from the final summed loss.  This does not work because larger losses overpower smaller losses.  A way to fix that is to add a scaling factor to each loss before summing.  Does not work in this scenario because the ranges for the losses change depending on the circuit and constraints.  The second way is to individually backpropagate each loss before one optimizer update.  The three models battle it this case.  The fix for this is to run an optimizer step after each loss backprop.  Therefore each loss is it's own model that takes shared parameters as input and returns an update of the parameters for use by the next loss backprop + opt step.\n",
    "\n",
    "Note:  At one point the `retain_graph = True` input for `loss.backward()` method was used to retain computation of the entire graph for all the losses before freeing from memory.  Useful for the case when having to call multiple loss.backward() in a row without an optimizer step.  Bascially adding all contributions of gradients from all losses to a shared parameter.  Unstable.\n",
    "\n",
    "Model struggles with large differences in values (1 vs 100 Ohms in the same circuit).  It needs some form of normalization.  Normalization needs to be treated as max of v_input is v_base and max of i_input is i_base and derive all other bases from i_base and v_base.  For example, r_base = v_base / i_base.\n",
    "\n",
    "Freezing parameters, especially resistance, allows the model to train itself from different perpectives.  This is done by zeroing the gradients for an entire set of parameters.  Freezing is always done for any \"known\" parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No inference therefore no testing!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Train Loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using combined losses is better than treating losses separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.0,2.0,499000.5\n",
      "epoch 1000 loss: 0.9360088855805665,0.00028040991406367915,1.8683673853879654\n",
      "epoch 2000 loss: 0.814407203316894,0.0005827217538164508,1.6241059983873876\n",
      "epoch 3000 loss: 0.7250472319790913,0.0006482581322349121,26.758232248037565\n",
      "epoch 4000 loss: 0.6555947992608031,0.0002488246313664469,1.3094890996955781\n",
      "epoch 5000 loss: 0.5996939050659047,0.00010906859910935182,1.197356379212347\n",
      "epoch 6000 loss: 0.5456948228648583,8.733383470857446e-05,2.3940272668182163\n",
      "epoch 7000 loss: 0.5063168709958683,7.861372139992968e-05,0.9787320239205627\n",
      "epoch 8000 loss: 0.46661339984080236,6.89927845324326e-05,0.9321286686882279\n",
      "epoch 9000 loss: 0.4297326277229181,6.035284572667445e-05,0.8584464378027813\n",
      "Done!\n",
      "potentials = (Parameter containing:\n",
      "tensor([[   0.0000],\n",
      "        [-369.9632]], dtype=torch.float64, requires_grad=True), 1)\n",
      "voltages = (Parameter containing:\n",
      "tensor([[-369.9579],\n",
      "        [ 369.9722]], dtype=torch.float64, requires_grad=True), 1)\n",
      "currents = (Parameter containing:\n",
      "tensor([[1.0000],\n",
      "        [0.3712]], dtype=torch.float64, requires_grad=True), tensor(0.7071, dtype=torch.float64))\n",
      "attributes = (Parameter containing:\n",
      "tensor([[-369.9548],\n",
      "        [1000.0000]], dtype=torch.float64, requires_grad=True), tensor(1.4142, dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "prev_loss = 0.1\n",
    "lt_prev_loss_kcl = 1000\n",
    "lt_prev_loss_kvl = 1000\n",
    "lt_prev_loss_res = 1000\n",
    "\n",
    "for t in range(epochs):\n",
    "\n",
    "    #set training mode\n",
    "    kcl_model.train()\n",
    "    kvl_model.train()\n",
    "    res_model.train()\n",
    "\n",
    "    # KVL\n",
    "    kvl_pred = kvl_model()\n",
    "    kvl_loss = loss_fn(kvl_pred, torch.zeros_like(kvl_pred))\n",
    "\n",
    "    # KCL\n",
    "    kcl_pred = kcl_model()\n",
    "    kcl_loss = loss_fn(kcl_pred, torch.zeros_like(kcl_pred))\n",
    "\n",
    "    # Elements\n",
    "    res_pred = res_model()\n",
    "    res_loss = loss_fn(res_pred, torch.zeros_like(res_pred))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    total_loss = res_loss + 1000*kcl_loss + kvl_loss\n",
    "\n",
    "    res_model.zero_grad()\n",
    "    kcl_model.zero_grad()\n",
    "    kvl_model.zero_grad()\n",
    "\n",
    "    total_loss.backward()\n",
    "\n",
    "    res_model.zero_known_grads()\n",
    "    kcl_model.zero_known_grads()\n",
    "    kvl_model.zero_known_grads()\n",
    "\n",
    "    res_opt.step()\n",
    "    kcl_opt.step()\n",
    "    kvl_opt.step()\n",
    "\n",
    "    # analyze steps and loss\n",
    "    max_loss = max(kcl_loss, kvl_loss, res_loss)\n",
    "    loss_change = abs(max_loss - prev_loss) / prev_loss\n",
    "    prev_loss = max_loss\n",
    "\n",
    "    if (t % (epochs/10)) == 0:\n",
    "        # print(f'epoch {t} loss = {max_loss} ({loss_change} per unit change)')\n",
    "        print(f'epoch {t} loss: {kcl_loss.item()},{kvl_loss.item()},{res_loss.item()}')\n",
    "        if kcl_loss > lt_prev_loss_kcl:\n",
    "            for g in kcl_opt.param_groups:\n",
    "                g['lr'] /= 2\n",
    "            # print(f'reducing kcl learning rate')\n",
    "        lt_prev_loss_kcl = kcl_loss\n",
    "\n",
    "        if kvl_loss > lt_prev_loss_kvl:\n",
    "            for g in kvl_opt.param_groups:\n",
    "                g['lr'] /= 2\n",
    "            # print(f'reducing kcl learning rate')\n",
    "        lt_prev_loss_kvl = kvl_loss\n",
    "\n",
    "        if res_loss > lt_prev_loss_res:\n",
    "            for g in res_opt.param_groups:\n",
    "                g['lr'] /= 2\n",
    "            # print(f'reducing res learning rate')\n",
    "        lt_prev_loss_res = res_loss\n",
    "\n",
    "    if max_loss < 1e-10:\n",
    "        print(f'epoch {t} loss = {max_loss} finished early for loss threshold')\n",
    "        break\n",
    "\n",
    "print(\"Done!\")\n",
    "print(f\"potentials = {pot_param}\")\n",
    "print(f\"voltages = {v_param}\")\n",
    "print(f\"currents = {i_param}\")\n",
    "print(f\"attributes = {attr_param}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:16:53) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3217f10b4e7366dd1a6cbf73464f125221bf8686d6dfc23b58c931b1c5e4bd4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
