{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import networkx as nx\n",
    "import copy\n",
    "import circuits as ckt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input Data for a Simple Circuit\n",
    "Circuit is an independent voltage source and a resistor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit with 2 nodes and 2 elements\n",
      "[0, 1]\n",
      "[(1 , 0), (1 , 0)]\n",
      "[(1, {}), (0, {})]\n",
      "[(1, 0, 0, {'kind': <Kinds.IVS: 0>, 'i': 0.1, 'v': None, 'attr': -2}), (1, 0, 1, {'kind': <Kinds.R: 2>, 'i': None, 'v': None, 'attr': None})]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vr = ckt.Circuit()\n",
    "v_source = vr.add_element(kind=ckt.Kinds.IVS)\n",
    "resistor = vr.add_element(kind=ckt.Kinds.R)\n",
    "v_source.connect(v_source.high, resistor.high)\n",
    "v_source.connect(v_source.low, resistor.low)\n",
    "v_source.attr = -2\n",
    "v_source.i = 0.1\n",
    "# resistor.i = 0.1\n",
    "print(vr)\n",
    "print(vr.nodes)\n",
    "print(vr.elements)\n",
    "vr.draw()\n",
    "print(vr.nx_graph().nodes().data())\n",
    "print(vr.nx_graph().edges(data=True,keys=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Sizes of Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of element currents, voltages, and attr = (2,1)\n",
      "size of node voltages = (2,1)\n"
     ]
    }
   ],
   "source": [
    "# create tensors for voltages, currents, and element attrs\n",
    "print(f'size of element currents, voltages, and attr = ({vr.num_elements()},1)')\n",
    "print(f'size of node voltages = ({vr.num_nodes()},1)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Circuit Inputs for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinds.IVS\n",
      "Kinds.R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\terry\\OneDrive\\Documents\\GitHub\\side_circuit\\ml\\circuits.py:64: FutureWarning: incidence_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  M_scipy = nx.incidence_matrix(G=self.nx_graph(),oriented=True)\n"
     ]
    }
   ],
   "source": [
    "input = ckt.Input(vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [ 1.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<Kinds.IVS: 0>: [True, False],\n",
       " <Kinds.ICS: 1>: [False, False],\n",
       " <Kinds.R: 2>: [False, True]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.kinds_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<Props.I: 0>: [True, False],\n",
       " <Props.V: 1>: [True, False],\n",
       " <Props.Attr: 2>: [True, False]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.knowns_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<Props.I: 0>: [0.1, 0.4054874717700453],\n",
       " <Props.V: 1>: [-2.0, 0.9059380952114919],\n",
       " <Props.Attr: 2>: [-2.0, 0.6075679437146172]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.inputs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1000],\n",
       "         [0.4055]]),\n",
       " tensor([[-2.0000],\n",
       "         [ 0.9059]]),\n",
       " tensor([[0.5038],\n",
       "         [0.9933]]),\n",
       " tensor([[-2.0000],\n",
       "         [ 0.6076]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.init_tensors()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(nn.Module):\n",
    "    def __init__(self, input: ckt.Input):\n",
    "        super().__init__()\n",
    "        self.input = input\n",
    "        i_in, v_in, pot_in, attr_in = self.input.init_tensors()\n",
    "        self.i = nn.Parameter(i_in.clone().detach())\n",
    "        self.v = nn.Parameter(v_in.clone().detach())\n",
    "        self.pot = nn.Parameter(pot_in.clone().detach())\n",
    "        self.attr = nn.Parameter(attr_in.clone().detach())\n",
    "\n",
    "    def forward(self):\n",
    "        current_error = self.kcl(input.M, self.i)\n",
    "        voltage_error = self.kvl(input.M, self.v, self.pot)\n",
    "        resistor_error = self.resistor(self.i, self.v, self.attr,\n",
    "                                        self.input.kinds_map[ckt.Kinds.R])\n",
    "        return current_error, voltage_error, resistor_error\n",
    "\n",
    "    def kcl(self, M, i):\n",
    "        current_error = M @ i\n",
    "        return current_error\n",
    "\n",
    "    def kvl(self,M,v,pot):\n",
    "        kvl_error = v - M.T @ pot\n",
    "        return kvl_error\n",
    "\n",
    "    def resistor(self,i,v,r,res_mask):\n",
    "        resistor_v_error = i[res_mask] * r[res_mask] - v[res_mask]\n",
    "        return resistor_v_error\n",
    "\n",
    "    def zero_known_grads(self):\n",
    "        if(self.i.grad != None):\n",
    "            self.i.grad[self.input.knowns_map[ckt.Props.I]] = 0\n",
    "        if(self.v.grad != None):\n",
    "            self.v.grad[self.input.knowns_map[ckt.Props.V]] = 0\n",
    "        if(self.attr.grad != None):\n",
    "            self.attr.grad[self.input.knowns_map[ckt.Props.Attr]] = 0\n",
    "\n",
    "    def zero_res_grads(self):\n",
    "        if(self.i.grad != None):\n",
    "            self.i.grad[self.input.kinds_map[ckt.Kinds.R]] = 0\n",
    "        if(self.v.grad != None):\n",
    "            self.v.grad[self.input.kinds_map[ckt.Kinds.R]] = 0\n",
    "        if(self.attr.grad != None):\n",
    "            self.attr.grad[self.input.kinds_map[ckt.Kinds.R]] = 0\n",
    "\n",
    "    def freeze_i_v(self):\n",
    "        self.i.requires_grad = False\n",
    "        self.v.requires_grad = False\n",
    "\n",
    "    def unfreeze_i_v(self):\n",
    "        self.i.requires_grad = True\n",
    "        self.v.requires_grad = True\n",
    "\n",
    "    def freeze_attr(self):\n",
    "        self.attr.requires_grad = False\n",
    "\n",
    "    def unfreeze_attr(self):\n",
    "        self.attr.requires_grad = True\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Instance of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Solver(input = input).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(),lr=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using combined losses is better than treating losses separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_i():\n",
    "    #set training mode\n",
    "    model.train()\n",
    "\n",
    "    kcl_err, _, _ = model()\n",
    "    kcl_loss = loss_fn(kcl_err, torch.zeros_like(kcl_err))\n",
    "\n",
    "    loss = kcl_loss\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    model.zero_known_grads()\n",
    "    optimizer.step()\n",
    "    \n",
    "    params = torch.cat(tuple(model.parameters()))\n",
    "\n",
    "    return loss,params.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_v():\n",
    "    #set training mode\n",
    "    model.train()\n",
    "\n",
    "    _, kvl_err, _ = model()\n",
    "    kvl_loss = loss_fn(kvl_err, torch.zeros_like(kvl_err))\n",
    "\n",
    "    loss = kvl_loss\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    model.zero_known_grads()\n",
    "    # model.zero_res_grads()\n",
    "    optimizer.step()\n",
    "    \n",
    "    params = torch.cat(tuple(model.parameters()))\n",
    "\n",
    "    return loss,params.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_unkown_element_attr():\n",
    "    #set training mode\n",
    "    model.train()\n",
    "\n",
    "    _, _, res_err = model()\n",
    "    res_loss = loss_fn(res_err, torch.zeros_like(res_err))\n",
    "\n",
    "    loss = res_loss\n",
    "\n",
    "    model.zero_grad()\n",
    "    model.freeze_i_v()\n",
    "    loss.backward()\n",
    "    model.zero_known_grads()\n",
    "    optimizer.step()\n",
    "    model.unfreeze_i_v()\n",
    "\n",
    "    params = torch.cat(tuple(model.parameters()))\n",
    "\n",
    "    return loss,params.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_i_v_from_element_attr():\n",
    "    #set training mode\n",
    "    model.train()\n",
    "\n",
    "    _, _, res_err = model()\n",
    "    res_loss = loss_fn(res_err, torch.zeros_like(res_err))\n",
    "\n",
    "    loss = res_loss\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    model.zero_known_grads()\n",
    "    optimizer.step()\n",
    "\n",
    "    params = torch.cat(tuple(model.parameters()))\n",
    "\n",
    "    return loss,params.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stable(prev:torch.Tensor,updated:torch.Tensor, pu_threshold:float):\n",
    "    abs_val = torch.abs(updated - prev)\n",
    "    prev_abs = torch.abs(prev)\n",
    "    pu_change = abs_val / prev_abs\n",
    "    # print(f' {abs_val} / {prev_abs} = {pu_change}')\n",
    "    pu_change_max = torch.max(pu_change)\n",
    "    ret_bool = pu_change_max < pu_threshold\n",
    "    return ret_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state 0 loss: 0.2555176019668579\n",
      "Done! at 946 epochs\n",
      "current = Parameter containing:\n",
      "tensor([[ 0.1000],\n",
      "        [-0.0384]], requires_grad=True)\n",
      "voltage = Parameter containing:\n",
      "tensor([[-2.0000],\n",
      "        [ 0.1012]], requires_grad=True)\n",
      "potential = Parameter containing:\n",
      "tensor([[ 1.6546],\n",
      "        [-0.3454]], requires_grad=True)\n",
      "attributes = Parameter containing:\n",
      "tensor([[-2.0000],\n",
      "        [-2.6390]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "state = 0\n",
    "th = 0.000001\n",
    "prev_loss = 0.1\n",
    "lt_prev_loss = 1000\n",
    "loss, params = smooth_i()\n",
    "print(f'init state {state} loss: {loss.item()}')\n",
    "\n",
    "prev_params = params\n",
    "\n",
    "model_is_stable = [False,False,False,False]\n",
    "\n",
    "# for t in range(epochs):\n",
    "t = 0\n",
    "while(False in model_is_stable):\n",
    "\n",
    "    if(t > epochs):\n",
    "        break\n",
    "    else:\n",
    "        t += 1\n",
    "\n",
    "    if(state == 0):\n",
    "        loss,params = smooth_i()\n",
    "        if(is_stable(prev_params, params, th)):\n",
    "            state = 1\n",
    "            model_is_stable[0] = True\n",
    "    elif(state == 1):\n",
    "        loss,params = smooth_v()\n",
    "        if(is_stable(prev_params, params, th)):\n",
    "            state = 2\n",
    "            model_is_stable[1] = True\n",
    "    elif(state == 2):\n",
    "        loss,params = update_unkown_element_attr()\n",
    "        if(is_stable(prev_params, params, th)):\n",
    "            state = 3\n",
    "            model_is_stable[2] = True\n",
    "    elif(state == 3):\n",
    "        # freeze previously updated element attr\n",
    "        # use element equation as loss function from v->i and i->v\n",
    "        loss,params = backprop_i_v_from_element_attr()\n",
    "        if(is_stable(prev_params, params, th)):\n",
    "            state = 0\n",
    "            model_is_stable[3] = True\n",
    "    else:\n",
    "        assert()\n",
    "\n",
    "    prev_params = params\n",
    "\n",
    "    # if (t % (epochs/10)) == 0:\n",
    "    #     state = ~state\n",
    "    \n",
    "    # analyze steps and loss\n",
    "    loss_change = abs(loss - prev_loss) / prev_loss\n",
    "    prev_loss = loss\n",
    "\n",
    "    if (t % (epochs/10)) == 0:\n",
    "        lt_prev_loss = loss\n",
    "\n",
    "print(f'Done! at {t} epochs')\n",
    "print(f\"current = {model.i}\")\n",
    "print(f\"voltage = {model.v}\")\n",
    "print(f\"potential = {model.pot}\")\n",
    "print(f\"attributes = {model.attr}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTPUT USING GRADIENT FREEZING\n",
    "\n",
    "1\n",
    "\n",
    "```python\n",
    "epoch 0 loss: 3.341080904006958\n",
    "epoch 1000 loss: 0.0\n",
    "epoch 2000 loss: 0.0\n",
    "epoch 3000 loss: 0.0\n",
    "epoch 4000 loss: 0.0\n",
    "epoch 5000 loss: 0.0\n",
    "epoch 6000 loss: 0.0\n",
    "epoch 7000 loss: 0.0\n",
    "epoch 8000 loss: 0.0\n",
    "epoch 9000 loss: 0.0\n",
    "Done!\n",
    "current = Parameter containing:\n",
    "tensor([[-0.5000],\n",
    "        [ 0.5000]], requires_grad=True)\n",
    "voltage = Parameter containing:\n",
    "tensor([[2.],\n",
    "        [2.]], requires_grad=True)\n",
    "potential = Parameter containing:\n",
    "tensor([[-0.7411],\n",
    "        [ 1.2589]], requires_grad=True)\n",
    "attributes = Parameter containing:\n",
    "tensor([[2.],\n",
    "        [4.]], requires_grad=True)\n",
    "```\n",
    "\n",
    "2\n",
    "\n",
    "\n",
    "```python\n",
    "epoch 0 loss: 5.810656547546387\n",
    "epoch 1000 loss: 3.552713678800501e-15\n",
    "epoch 2000 loss: 3.552713678800501e-15\n",
    "epoch 3000 loss: 2.7913847588934004e-07\n",
    "epoch 4000 loss: 1.4210854715202004e-14\n",
    "epoch 5000 loss: 1.7408297026122455e-11\n",
    "epoch 6000 loss: 0.0\n",
    "epoch 7000 loss: 0.0\n",
    "epoch 8000 loss: 0.0\n",
    "epoch 9000 loss: 0.0\n",
    "Done!\n",
    "params = [('i', Parameter containing:\n",
    "tensor([[-1.],\n",
    "        [ 1.]], requires_grad=True)), ('v', Parameter containing:\n",
    "tensor([[2.],\n",
    "        [2.]], requires_grad=True)), ('pot', Parameter containing:\n",
    "tensor([[-0.3692],\n",
    "        [ 1.6308]], requires_grad=True)), ('attr', Parameter containing:\n",
    "tensor([[2.],\n",
    "        [2.]], requires_grad=True))]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3217f10b4e7366dd1a6cbf73464f125221bf8686d6dfc23b58c931b1c5e4bd4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
