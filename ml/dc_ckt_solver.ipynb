{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import networkx as nx\n",
    "import copy\n",
    "import circuits as ckt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input Data for a Simple Circuit\n",
    "Circuit is an independent voltage source and a resistor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit with 2 nodes and 2 elements\n",
      "[0, 1]\n",
      "[(1 , 0), (1 , 0)]\n",
      "[(1, {}), (0, {})]\n",
      "[(1, 0, 0, {'kind': <Kinds.IVS: 0>, 'i': None, 'v': None, 'attr': 2}), (1, 0, 1, {'kind': <Kinds.R: 2>, 'i': 0.001, 'v': None, 'attr': None})]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vr = ckt.Circuit()\n",
    "v_source = vr.add_element(kind=ckt.Kinds.IVS)\n",
    "resistor = vr.add_element(kind=ckt.Kinds.R)\n",
    "v_source.connect(v_source.high, resistor.high)\n",
    "v_source.connect(v_source.low, resistor.low)\n",
    "v_source.attr = 2\n",
    "resistor.i = 0.001\n",
    "print(vr)\n",
    "print(vr.nodes)\n",
    "print(vr.elements)\n",
    "vr.draw()\n",
    "print(vr.nx_graph().nodes().data())\n",
    "print(vr.nx_graph().edges(data=True,keys=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Sizes of Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of element currents, voltages, and attr = (2,1)\n",
      "size of node voltages = (2,1)\n"
     ]
    }
   ],
   "source": [
    "# create tensors for voltages, currents, and element attrs\n",
    "print(f'size of element currents, voltages, and attr = ({vr.num_elements()},1)')\n",
    "print(f'size of node voltages = ({vr.num_nodes()},1)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Circuit Inputs for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinds.IVS\n",
      "Kinds.R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\terry\\OneDrive\\Documents\\GitHub\\side_circuit\\ml\\circuits.py:64: FutureWarning: incidence_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  M_scipy = nx.incidence_matrix(G=self.nx_graph(),oriented=True)\n"
     ]
    }
   ],
   "source": [
    "input = ckt.Input(vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [ 1.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<Kinds.IVS: 0>: [True, False],\n",
       " <Kinds.ICS: 1>: [False, False],\n",
       " <Kinds.R: 2>: [False, True]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.kinds_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<Props.I: 0>: [False, True],\n",
       " <Props.V: 1>: [True, False],\n",
       " <Props.Attr: 2>: [True, False]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.knowns_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<Props.I: 0>: [0.20411150296470304, 0.001],\n",
       " <Props.V: 1>: [2.0, 0.9157723305840797],\n",
       " <Props.Attr: 2>: [2.0, 0.44676224655091024]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.inputs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2041],\n",
       "         [0.0010]]),\n",
       " tensor([[2.0000],\n",
       "         [0.9158]]),\n",
       " tensor([[0.0432],\n",
       "         [0.4618]]),\n",
       " tensor([[2.0000],\n",
       "         [0.4468]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.init_tensors()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(nn.Module):\n",
    "    def __init__(self, input: ckt.Input):\n",
    "        super().__init__()\n",
    "        self.input = input\n",
    "        i_in, v_in, pot_in, attr_in = self.input.init_tensors()\n",
    "        self.i = nn.Parameter(i_in.clone().detach())\n",
    "        self.v = nn.Parameter(v_in.clone().detach())\n",
    "        self.pot = nn.Parameter(pot_in.clone().detach())\n",
    "        self.attr = nn.Parameter(attr_in.clone().detach())\n",
    "\n",
    "    def forward(self):\n",
    "        current_error = self.kcl(input.M, self.i)\n",
    "        voltage_error = self.kvl(input.M, self.v, self.pot)\n",
    "        resistor_error = self.resistor(self.i, self.v, self.attr)\n",
    "        return current_error, voltage_error, resistor_error\n",
    "\n",
    "    def kcl(self, M, i):\n",
    "        current_error = M @ i\n",
    "        return current_error\n",
    "\n",
    "    def kvl(self,M,v,pot):\n",
    "        kvl_error = v - M.T @ pot\n",
    "        return kvl_error\n",
    "\n",
    "    def resistor(self,i,v,r):\n",
    "        resistor_v_error = i * r - v\n",
    "        return resistor_v_error\n",
    "\n",
    "    def zero_kcl_known_grads(self):\n",
    "        self.i.grad[self.input.knowns_map[ckt.Props.I]] = 0\n",
    "        \n",
    "    def zero_kvl_known_grads(self):\n",
    "        self.v.grad[self.input.knowns_map[ckt.Props.V]] = 0\n",
    "\n",
    "    def zero_res_known_grads(self):\n",
    "        self.v.grad[self.input.knowns_map[ckt.Props.V]] = 0\n",
    "        self.i.grad[self.input.knowns_map[ckt.Props.I]] = 0\n",
    "        self.attr.grad[self.input.knowns_map[ckt.Props.Attr]] = 0\n",
    "\n",
    "    def zero_known_grads(self):\n",
    "        self.zero_kcl_known_grads()\n",
    "        self.zero_kvl_known_grads()\n",
    "        self.zero_res_known_grads()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Instance of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Solver(input = input).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(),lr=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is multitask learning since there are multiple losses accessing common, hard parameters.  By separating the losses, Adam optimizer can use different learning rates of different parameter groups.  Each loss is associated with a key equation for solving circuits (e.g. KCL).  There are three ways to backpropagate the losses.  \n",
    "\n",
    "First is the common way.  Calculate all losses, sum them, then backpropogate from the final summed loss.  This does not work because larger losses overpower smaller losses.  A way to fix that is to add a scaling factor to each loss before summing.  Does not work in this scenario because the ranges for the losses change depending on the circuit and constraints.  The second way is to individually backpropagate each loss before one optimizer update.  The three models battle it this case.  The fix for this is to run an optimizer step after each loss backprop.  Therefore each loss is it's own model that takes shared parameters as input and returns an update of the parameters for use by the next loss backprop + opt step.\n",
    "\n",
    "Note:  At one point the `retain_graph = True` input for `loss.backward()` method was used to retain computation of the entire graph for all the losses before freeing from memory.  Useful for the case when having to call multiple loss.backward() in a row without an optimizer step.  Bascially adding all contributions of gradients from all losses to a shared parameter.  Unstable.\n",
    "\n",
    "Model struggles with large differences in values (1 vs 100 Ohms in the same circuit).  It needs some form of normalization.  Normalization needs to be treated as max of v_input is v_base and max of i_input is i_base and derive all other bases from i_base and v_base.  For example, r_base = v_base / i_base.\n",
    "\n",
    "Freezing parameters, especially resistance, allows the model to train itself from different perpectives.  This is done by zeroing the gradients for an entire set of parameters.  Freezing is always done for any \"known\" parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using combined losses is better than treating losses separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 3.52864670753479\n",
      "epoch 1000 loss: 0.9088379144668579\n",
      "epoch 2000 loss: 0.7273942828178406\n",
      "epoch 3000 loss: 0.6754524111747742\n",
      "epoch 4000 loss: 0.6683515310287476\n",
      "epoch 5000 loss: 0.6682814955711365\n",
      "epoch 6000 loss: 0.6684752702713013\n",
      "epoch 7000 loss: 0.6680006384849548\n",
      "epoch 8000 loss: 0.6683152914047241\n",
      "epoch 9000 loss: 0.6680006384849548\n",
      "Done!\n",
      "params = [Parameter containing:\n",
      "tensor([[0.6663],\n",
      "        [0.0010]], requires_grad=True), Parameter containing:\n",
      "tensor([[2.0000],\n",
      "        [2.0004]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.6830],\n",
      "        [ 1.3163]], requires_grad=True), Parameter containing:\n",
      "tensor([[   2.0000],\n",
      "        [1999.9995]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "prev_loss = 0.1\n",
    "lt_prev_loss = 1000\n",
    "\n",
    "for t in range(epochs):\n",
    "\n",
    "    #set training mode\n",
    "    model.train()\n",
    "\n",
    "    i_error, v_error, r_error = model()\n",
    "    i_loss = loss_fn(i_error, torch.zeros_like(i_error))\n",
    "    v_loss = loss_fn(v_error, torch.zeros_like(v_error))\n",
    "    r_loss = loss_fn(r_error, torch.zeros_like(r_error))\n",
    "\n",
    "    loss = i_loss + v_loss + r_loss\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    model.zero_known_grads()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    # analyze steps and loss\n",
    "    loss_change = abs(loss - prev_loss) / prev_loss\n",
    "    prev_loss = loss\n",
    "\n",
    "    if (t % (epochs/10)) == 0:\n",
    "        print(f'epoch {t} loss: {loss.item()}')\n",
    "        if loss > lt_prev_loss:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] /= 2\n",
    "        lt_prev_loss = loss\n",
    "\n",
    "    # if (loss_change < 1e-45):\n",
    "    #     print(f'epoch {t} loss = {loss} finished early for loss change')\n",
    "    #     break\n",
    "\n",
    "    if loss < 1e-10:\n",
    "        print(f'epoch {t} loss = {loss} finished early for loss threshold')\n",
    "        break\n",
    "\n",
    "print(\"Done!\")\n",
    "print(f\"params = {list(model.parameters())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3217f10b4e7366dd1a6cbf73464f125221bf8686d6dfc23b58c931b1c5e4bd4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
