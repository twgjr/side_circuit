{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import networkx as nx\n",
    "import copy\n",
    "import circuits as ckt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input Data for a Simple Circuit\n",
    "Circuit is an independent voltage source and a resistor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit with 2 nodes and 2 elements\n",
      "[0, 1]\n",
      "[(1 , 0), (1 , 0)]\n",
      "[(1, {}), (0, {})]\n",
      "[(1, 0, 0, {'kind': 0, 'i': None, 'v': None, 'attr': 2}), (1, 0, 1, {'kind': 1, 'i': 0.5, 'v': None, 'attr': None})]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vr = ckt.Circuit()\n",
    "v_source = vr.add_element(kind=ckt.Kinds.IVS.value)\n",
    "resistor = vr.add_element(kind=ckt.Kinds.R.value)\n",
    "v_source.connect(v_source.high, resistor.high)\n",
    "v_source.connect(v_source.low, resistor.low)\n",
    "v_source.attr = 2\n",
    "resistor.i = 0.5\n",
    "# v_source.low.p = 0\n",
    "print(vr)\n",
    "print(vr.nodes)\n",
    "print(vr.elements)\n",
    "vr.draw()\n",
    "print(vr.nx_graph().nodes().data())\n",
    "print(vr.nx_graph().edges(data=True,keys=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Sizes of Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of element currents, voltages, and attr = (2,1)\n",
      "size of node voltages = (2,1)\n"
     ]
    }
   ],
   "source": [
    "print(f'size of element currents, voltages, and attr = ({vr.num_elements()},1)')\n",
    "print(f'size of node voltages = ({vr.num_nodes()},1)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\terry\\OneDrive\\Documents\\GitHub\\side_circuit\\ml\\circuits.py:77: FutureWarning: incidence_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  M_scipy = nx.incidence_matrix(G=self.nx_graph(),oriented=True)\n"
     ]
    }
   ],
   "source": [
    "input_test = ckt.Input(vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [ 1.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.M"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit Theory Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.5000]]),\n",
       " tensor([[0.],\n",
       "         [0.]]),\n",
       " tensor([[0.],\n",
       "         [0.]]),\n",
       " tensor([[2.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.init_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [ True]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~input_test.known_masks()[3].to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0., -1.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.element_row(input_test.init_tensors()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: tensor([[1.],\n",
       "         [0.]]),\n",
       " 1: tensor([[0.],\n",
       "         [1.]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.kind_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tensor([[True],\n",
    "                    [True]], dtype=torch.bool)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10],\n",
       "        [20]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.tensor([[10],\n",
    "                    [20]])\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10],\n",
       "        [20]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor[~mask] = 4\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.s()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solve(nn.Module):\n",
    "    ''' \n",
    "    Sparse Tableau Formulation of circuit analysis, modeled as a machine learning\n",
    "    problem to learn element attributes using backprop and optimization.\n",
    "    '''\n",
    "    def __init__(self, input: ckt.Input):\n",
    "        super().__init__()\n",
    "        self.input = input\n",
    "        _, _, _, attr_in = self.input.init_tensors()\n",
    "        self.attr = nn.Parameter(attr_in.clone().detach())\n",
    "\n",
    "    def forward(self):\n",
    "        A,b = self.build()\n",
    "        solution = torch.linalg.lstsq(A,b).solution\n",
    "        #calc_attr = self.calc_attrs(solution)\n",
    "        return solution#, calc_attr\n",
    "            \n",
    "    def zero_known_grads(self):\n",
    "        _,_,_,attr = self.input.known_masks()\n",
    "        self.attr.grad[attr.to(torch.bool)] = 0\n",
    "\n",
    "    def build(self):\n",
    "        # inputs\n",
    "        i_in, v_in, _, attr_in = self.input.init_tensors()\n",
    "        kind_map = self.input.kind_map()\n",
    "        is_s_mask = kind_map[ckt.Kinds.IVS.value]\n",
    "        is_r_mask = kind_map[ckt.Kinds.R.value]\n",
    "        _,_,_,attr_known = self.input.known_masks()\n",
    "        attr_known = attr_known.to(torch.bool)\n",
    "        is_r_mask_z, is_r_mask_y, is_s_mask_y = self.input.rs_mask(kind_map)\n",
    "        s = self.input.s()\n",
    "        M = self.input.M\n",
    "        num_elements = M.shape[1]\n",
    "                \n",
    "        # A matrix\n",
    "        kcl_row = torch.cat(tensors=(M,\n",
    "                                    torch.zeros_like(M),\n",
    "                                    torch.zeros_like(M)),dim=1)\n",
    "        kvl_row = torch.cat(tensors=(torch.zeros_like(M),\n",
    "                                    torch.eye(num_elements),\n",
    "                                    -M.T),dim=1)\n",
    "        # e_row = self.input.element_row()\n",
    "        e_row = self.input.element_row(self.attr)\n",
    "        A = torch.cat(tensors=(kcl_row,kvl_row,e_row), dim=0)\n",
    "\n",
    "        # b matrix\n",
    "        kcl_zeros = torch.zeros_like(i_in)\n",
    "        kvl_zeros = torch.zeros_like(v_in)\n",
    "        b = torch.cat(tensors=(kvl_zeros,kcl_zeros,s), dim=0)\n",
    "        \n",
    "        return A,b\n",
    "\n",
    "    def calc_attrs(self, solution: torch.Tensor):\n",
    "        kind_masks = self.input.kind_map()\n",
    "        ivs_mask: torch.Tensor = kind_masks[ckt.Kinds.IVS.value].to(torch.bool)\n",
    "        r_mask: torch.Tensor  = kind_masks[ckt.Kinds.R.value].to(torch.bool)\n",
    "        num_elements = r_mask.shape[0]\n",
    "        \n",
    "        i = solution[:num_elements,:]\n",
    "        v = solution[num_elements:2*num_elements,:]\n",
    "        \n",
    "        ret_attrs = torch.zeros(size=(num_elements,1))\n",
    "\n",
    "        ret_attrs[ivs_mask] = v[ivs_mask]\n",
    "        ret_attrs[r_mask] = v[r_mask]/i[r_mask]\n",
    "\n",
    "        return ret_attrs\n",
    "\n",
    "    # def attr_error(self, calc_attrs):\n",
    "    #     _, _, _, mask = self.input.known_masks()\n",
    "    #     _, _, _, pred_attrs = self.attr()\n",
    "    #     attrs[mask.to(torch.bool)]\n",
    "    #     return truths[mask.to(torch.bool)] - "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Instance of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[2.],\n",
       "         [1.]], requires_grad=True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = ckt.Input(vr)\n",
    "model = Solve(input=input)\n",
    "list(model.parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(),lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No inference therefore no testing!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mask():\n",
    "    # _, _, _, attr_known = input.known_masks()\n",
    "    # attr_bool = attr_known.to(torch.bool)\n",
    "    # return attr_bool\n",
    "    masks = input.known_masks()\n",
    "    mask_list = []\n",
    "    for m in range(len(masks)):\n",
    "        if(m==2):\n",
    "            continue\n",
    "        mask_list.append(masks[m].to(torch.bool))\n",
    "    mask_tuple = tuple(mask_list)\n",
    "    return torch.cat(tensors=(mask_tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truth_vals():\n",
    "    # _, _, _, attr_in = input.init_tensors()\n",
    "    # return attr_in\n",
    "    truths = input.init_tensors()\n",
    "    truth_list = []\n",
    "    for m in range(len(truths)):\n",
    "        if(m==2):\n",
    "            continue\n",
    "        truth_list.append(truths[m])\n",
    "    truth_tuple = tuple(truth_list)\n",
    "    return torch.cat(tensors=(truth_tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 2.0000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_vals()[loss_mask()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 5.625000953674316\n",
      "epoch 340 loss = 4.500120639801025 finished early for loss change\n",
      "Done!\n",
      "pred tensor([[-0.5154],\n",
      "        [ 0.5154],\n",
      "        [ 2.0000],\n",
      "        [ 2.0000],\n",
      "        [-1.0000],\n",
      "        [ 1.0000]], grad_fn=<LinalgLstsqBackward0>)\n",
      "truth tensor([0.5000, 2.0000])\n",
      "attr [Parameter containing:\n",
      "tensor([[2.0000],\n",
      "        [3.8812]], requires_grad=True)]\n",
      "pred known tensor([ 0.5154, -1.0000], grad_fn=<IndexBackward0>)\n",
      "true vals known tensor([0.5000, 2.0000])\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "prev_loss = 0.1\n",
    "lt_prev_loss = 1000\n",
    "\n",
    "true_vals = truth_vals()\n",
    "\n",
    "knowns_mask = loss_mask()\n",
    "\n",
    "for t in range(epochs):\n",
    "\n",
    "    #set training mode\n",
    "    model.train()\n",
    "\n",
    "    pred = model()\n",
    "    loss = loss_fn(pred[knowns_mask], true_vals[knowns_mask])\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    # loss.backward(retain_graph=True)\n",
    "    loss.backward(retain_graph=False)\n",
    "\n",
    "    model.zero_known_grads()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    # analyze steps and loss\n",
    "    loss_change = abs(loss - prev_loss) / prev_loss\n",
    "    prev_loss = loss\n",
    "\n",
    "    if (t % (epochs/10)) == 0:\n",
    "        # print(f'epoch {t} loss = {max_loss} ({loss_change} per unit change)')\n",
    "        print(f'epoch {t} loss: {loss.item()}')\n",
    "        if loss > lt_prev_loss:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] /= 2\n",
    "            # print(f'reducing kcl learning rate')\n",
    "        lt_prev_loss = loss\n",
    "\n",
    "    if (loss_change < 1e-30):\n",
    "        print(f'epoch {t} loss = {loss} finished early for loss change')\n",
    "        break\n",
    "\n",
    "    if loss < 1e-10:\n",
    "        print(f'epoch {t} loss = {loss} finished early for loss threshold')\n",
    "        break\n",
    "\n",
    "print(\"Done!\")\n",
    "print(f'pred {pred}')\n",
    "print(f'truth {true_vals[knowns_mask]}')\n",
    "print(f'attr {list(model.parameters())}')\n",
    "print(f'pred known {pred[knowns_mask]}')\n",
    "print(f'true vals known {true_vals[knowns_mask]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0656442642211914"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3217f10b4e7366dd1a6cbf73464f125221bf8686d6dfc23b58c931b1c5e4bd4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
