{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import networkx as nx\n",
    "import copy\n",
    "import circuits as ckt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input Data for a Simple Circuit\n",
    "Circuit is an independent voltage source and a resistor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit with 2 nodes and 2 elements\n",
      "[0, 1]\n",
      "[(0 , 1), (1 , 0)]\n",
      "[(0, {}), (1, {})]\n",
      "[(0, 1, 0, {'kind': 0, 'i': None, 'v': None, 'attr': 10}), (1, 0, 0, {'kind': 1, 'i': None, 'v': None, 'attr': 5})]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vr = ckt.Circuit()\n",
    "v_source = vr.add_element(kind=ckt.Kinds.IVS.value)\n",
    "resistor = vr.add_element(kind=ckt.Kinds.R.value)\n",
    "v_source.connect(v_source.high, resistor.low)\n",
    "v_source.connect(v_source.low, resistor.high)\n",
    "v_source.attr = 10\n",
    "resistor.attr = 5\n",
    "# v_source.low.p = 0\n",
    "print(vr)\n",
    "print(vr.nodes)\n",
    "print(vr.elements)\n",
    "vr.draw()\n",
    "print(vr.nx_graph().nodes().data())\n",
    "print(vr.nx_graph().edges(data=True,keys=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Sizes of Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of element currents, voltages, and attr = (2,1)\n",
      "size of node voltages = (2,1)\n"
     ]
    }
   ],
   "source": [
    "print(f'size of element currents, voltages, and attr = ({vr.num_elements()},1)')\n",
    "print(f'size of node voltages = ({vr.num_nodes()},1)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\terry\\OneDrive\\Documents\\GitHub\\side_circuit\\ml\\circuits.py:77: FutureWarning: incidence_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  M_scipy = nx.incidence_matrix(G=self.nx_graph(),oriented=True)\n"
     ]
    }
   ],
   "source": [
    "input_test = ckt.Input(vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  1.],\n",
       "        [ 1., -1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.M"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit Theory Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.],\n",
       "         [0.]]),\n",
       " tensor([[0.],\n",
       "         [0.]]),\n",
       " tensor([[0.],\n",
       "         [0.]]),\n",
       " tensor([[10.],\n",
       "         [ 5.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.prop_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0., -5.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.element_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: tensor([[1.],\n",
       "         [0.]]),\n",
       " 1: tensor([[0.],\n",
       "         [1.]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.kind_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [ 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.s()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solve(nn.Module):\n",
    "    ''' \n",
    "    Sparse Tableau Formulation of circuit analysis, modeled as a machine learning\n",
    "    problem to learn element attributes using backprop and optimization.\n",
    "    '''\n",
    "    def __init__(self, input: ckt.Input):\n",
    "        super().__init__()\n",
    "        self.input = input\n",
    "        i_in, v_in, pot_in, attr_in = self.input.prop_tensors()\n",
    "        self.attr = nn.Parameter(attr_in)\n",
    "\n",
    "    def forward(self):\n",
    "        A,b = self.build()\n",
    "        print(f'A {A}')\n",
    "        print(f'b {b}')\n",
    "        solution = torch.linalg.lstsq(A,b).solution\n",
    "        print(f'x {solution}')\n",
    "        calc_attrs = self.calc_attrs(solution)\n",
    "        return calc_attrs\n",
    "            \n",
    "    def zero_known_grads(self, attr_known):\n",
    "        self.attr.grad[attr_known] = 0\n",
    "\n",
    "    def build(self):\n",
    "        # inputs\n",
    "        i_in, v_in, pot_in, attr_in = self.input.prop_tensors()\n",
    "        kind_map = self.input.kind_map()\n",
    "        is_s_mask = kind_map[ckt.Kinds.IVS.value]\n",
    "        is_r_mask = kind_map[ckt.Kinds.R.value]\n",
    "        i_known, v_known, pot_known , attr_known = self.input.known_masks()\n",
    "        attr_known = attr_known.to(torch.bool)\n",
    "        is_r_mask_z, is_r_mask_y, is_s_mask_y = self.input.rs_mask(kind_map)\n",
    "        s = self.input.s()\n",
    "        M = self.input.M\n",
    "        num_elements = M.shape[1]\n",
    "                \n",
    "        # A matrix\n",
    "        kcl_row = torch.cat(tensors=(M,\n",
    "                                    torch.zeros_like(M),\n",
    "                                    torch.zeros_like(M)),dim=1)\n",
    "        kvl_row = torch.cat(tensors=(torch.zeros_like(M),\n",
    "                                    torch.eye(num_elements),\n",
    "                                    -M.T),dim=1)\n",
    "        e_row = self.input.element_row()\n",
    "        A = torch.cat(tensors=(kcl_row,kvl_row,e_row), dim=0)\n",
    "\n",
    "        # b matrix\n",
    "        kcl_zeros = torch.zeros_like(i_in)\n",
    "        kvl_zeros = torch.zeros_like(v_in)\n",
    "        b = torch.cat(tensors=(kvl_zeros,kcl_zeros,s), dim=0)\n",
    "        \n",
    "        return A,b\n",
    "\n",
    "    def calc_attrs(self, solution: torch.Tensor):\n",
    "        kind_masks = self.input.kind_map()\n",
    "        ivs_mask: torch.Tensor = kind_masks[ckt.Kinds.IVS.value].to(torch.bool)\n",
    "        r_mask: torch.Tensor  = kind_masks[ckt.Kinds.R.value].to(torch.bool)\n",
    "        num_elements = r_mask.shape[0]\n",
    "        \n",
    "        i = solution[:num_elements,:]\n",
    "        v = solution[num_elements:2*num_elements,:]\n",
    "        \n",
    "        ret_attrs = torch.zeros(size=(num_elements,1))\n",
    "\n",
    "        ret_attrs[ivs_mask] = v[ivs_mask]\n",
    "        ret_attrs[r_mask] = i[r_mask]*v[r_mask]\n",
    "\n",
    "        return ret_attrs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Instance of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[10.],\n",
       "         [ 5.]], requires_grad=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = ckt.Input(vr)\n",
    "model = Solve(input=input)\n",
    "list(model.parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(),lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No inference therefore no testing!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_known_mask():\n",
    "    _, _, _, attr_known = input.known_masks()\n",
    "    attr_bool = attr_known.to(torch.bool)\n",
    "    return attr_bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_truth():\n",
    "    _, _, _, attr_in = input.prop_tensors()\n",
    "    return attr_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  5.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_truth()[attr_known_mask()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tensor tensor([[-1.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 1., -1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  1., -1.],\n",
      "        [ 0.,  0.,  0.,  1., -1.,  1.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0., -5.,  0.,  1.,  0.,  0.]])\n",
      "b tensor tensor([[ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [10.],\n",
      "        [ 0.]])\n",
      "solution tensor([[ -2.0000],\n",
      "        [ -2.0000],\n",
      "        [ 10.0000],\n",
      "        [-10.0000],\n",
      "        [ -5.0000],\n",
      "        [  5.0000]])\n",
      "tensor([10.0000, 20.0000])\n",
      "tensor([10.,  5.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     22\u001b[0m \u001b[39m# loss.backward(retain_graph=True)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m loss\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     25\u001b[0m model\u001b[39m.\u001b[39mzero_known_grads()\n\u001b[0;32m     27\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\terry\\.conda\\envs\\ml\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\terry\\.conda\\envs\\ml\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "prev_loss = 0.1\n",
    "lt_prev_loss = 1000\n",
    "\n",
    "attr_true = attr_truth()\n",
    "\n",
    "knowns_cat = attr_known_mask()\n",
    "\n",
    "for t in range(epochs):\n",
    "\n",
    "    #set training mode\n",
    "    model.train()\n",
    "\n",
    "    pred = model()\n",
    "    print(pred[knowns_cat])\n",
    "    print(attr_true[knowns_cat])\n",
    "    loss = loss_fn(pred[knowns_cat], attr_true[knowns_cat])\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    # loss.backward(retain_graph=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    model.zero_known_grads()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    # analyze steps and loss\n",
    "    loss_change = abs(loss - prev_loss) / prev_loss\n",
    "    prev_loss = loss\n",
    "\n",
    "    if (t % (epochs/10)) == 0:\n",
    "        # print(f'epoch {t} loss = {max_loss} ({loss_change} per unit change)')\n",
    "        print(f'epoch {t} loss: {loss.item()}')\n",
    "        if loss > lt_prev_loss:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] /= 2\n",
    "            # print(f'reducing kcl learning rate')\n",
    "        lt_prev_loss = loss\n",
    "\n",
    "    if loss < 1e-10:\n",
    "        print(f'epoch {t} loss = {loss} finished early for loss threshold')\n",
    "        break\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3217f10b4e7366dd1a6cbf73464f125221bf8686d6dfc23b58c931b1c5e4bd4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
