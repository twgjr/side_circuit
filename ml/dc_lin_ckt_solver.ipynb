{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import networkx as nx\n",
    "import copy\n",
    "import circuits as ckt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input Data for a Simple Circuit\n",
    "Circuit is an independent voltage source and a resistor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit with 2 nodes and 2 elements\n",
      "[0, 1]\n",
      "[(1 , 0), (1 , 0)]\n",
      "[(1, {}), (0, {})]\n",
      "[(1, 0, 0, {'kind': 0, 'i': None, 'v': None, 'attr': 2}), (1, 0, 1, {'kind': 1, 'i': 0.5, 'v': None, 'attr': None})]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vr = ckt.Circuit()\n",
    "v_source = vr.add_element(kind=ckt.Kinds.IVS.value)\n",
    "resistor = vr.add_element(kind=ckt.Kinds.R.value)\n",
    "v_source.connect(v_source.high, resistor.high)\n",
    "v_source.connect(v_source.low, resistor.low)\n",
    "v_source.attr = 2\n",
    "resistor.i = 0.5\n",
    "print(vr)\n",
    "print(vr.nodes)\n",
    "print(vr.elements)\n",
    "vr.draw()\n",
    "print(vr.nx_graph().nodes().data())\n",
    "print(vr.nx_graph().edges(data=True,keys=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Sizes of Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of element currents, voltages, and attr = (2,1)\n",
      "size of node voltages = (2,1)\n"
     ]
    }
   ],
   "source": [
    "print(f'size of element currents, voltages, and attr = ({vr.num_elements()},1)')\n",
    "print(f'size of node voltages = ({vr.num_nodes()},1)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\terry\\OneDrive\\Documents\\GitHub\\side_circuit\\ml\\circuits.py:62: FutureWarning: incidence_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  M_scipy = nx.incidence_matrix(G=self.nx_graph(),oriented=True)\n"
     ]
    }
   ],
   "source": [
    "input_test = ckt.Input(vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [ 1.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.M"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit Theory Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000],\n",
       "         [0.5000]]),\n",
       " tensor([[1.],\n",
       "         [1.]]),\n",
       " tensor([[1.],\n",
       "         [1.]]),\n",
       " tensor([[2.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.init_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [ True]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~input_test.known_masks()[2].to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0., -1.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.element_row(input_test.init_tensors()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: tensor([[1.],\n",
       "         [0.]]),\n",
       " 1: tensor([[0.],\n",
       "         [1.]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.kind_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tensor([[True],\n",
    "                    [True]], dtype=torch.bool)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10],\n",
       "        [20]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.tensor([[10],\n",
    "                    [20]])\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10],\n",
       "        [20]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor[~mask] = 4\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test.s()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solve(nn.Module):\n",
    "    ''' \n",
    "    Sparse Tableau Formulation of circuit analysis, modeled as a machine learning\n",
    "    problem to learn element attributes using backprop and optimization.\n",
    "    '''\n",
    "    def __init__(self, input: ckt.Input):\n",
    "        super().__init__()\n",
    "        self.input = input\n",
    "        _, _, _, attr_in = self.input.init_tensors()\n",
    "        self.attr = nn.Parameter(attr_in.clone().detach())\n",
    "\n",
    "    def forward(self):\n",
    "        A,b = self.build()\n",
    "        solution = torch.linalg.lstsq(A,b).solution\n",
    "        #calc_attr = self.calc_attrs(solution)\n",
    "        return solution#, calc_attr\n",
    "            \n",
    "    def zero_known_grads(self):\n",
    "        _,_,attr = self.input.known_masks()\n",
    "        self.attr.grad[attr.to(torch.bool)] = 0\n",
    "\n",
    "    def build(self):\n",
    "        # inputs\n",
    "        i_in, v_in, _, attr_in = self.input.init_tensors()\n",
    "        kind_map = self.input.kind_map()\n",
    "        is_s_mask = kind_map[ckt.Kinds.IVS.value]\n",
    "        is_r_mask = kind_map[ckt.Kinds.R.value]\n",
    "        is_r_mask_z, is_r_mask_y, is_s_mask_y = self.input.rs_mask(kind_map)\n",
    "        s = self.input.s()\n",
    "        M = self.input.M\n",
    "        num_elements = self.input.circuit.num_elements()\n",
    "                \n",
    "        # A matrix\n",
    "        kcl_row = torch.cat(tensors=(M,\n",
    "                                    torch.zeros_like(M),\n",
    "                                    torch.zeros_like(M)),dim=1)\n",
    "        kvl_row = torch.cat(tensors=(torch.zeros_like(M),\n",
    "                                    torch.eye(num_elements),\n",
    "                                    -M.T),dim=1)\n",
    "        # e_row = self.input.element_row()\n",
    "        e_row = self.input.element_row(self.attr)\n",
    "        A = torch.cat(tensors=(kcl_row,kvl_row,e_row), dim=0)\n",
    "\n",
    "        # b matrix\n",
    "        kcl_zeros = torch.zeros_like(i_in)\n",
    "        kvl_zeros = torch.zeros_like(v_in)\n",
    "        b = torch.cat(tensors=(kvl_zeros,kcl_zeros,s), dim=0)\n",
    "        \n",
    "        return A,b\n",
    "\n",
    "    def calc_attrs(self, solution: torch.Tensor):\n",
    "        kind_masks = self.input.kind_map()\n",
    "        ivs_mask: torch.Tensor = kind_masks[ckt.Kinds.IVS.value].to(torch.bool)\n",
    "        r_mask: torch.Tensor  = kind_masks[ckt.Kinds.R.value].to(torch.bool)\n",
    "        num_elements = self.input.circuit.num_elements()\n",
    "        \n",
    "        i = solution[:num_elements,:]\n",
    "        v = solution[num_elements:2*num_elements,:]\n",
    "        \n",
    "        ret_attrs = torch.zeros(size=(num_elements,1))\n",
    "\n",
    "        ret_attrs[ivs_mask] = v[ivs_mask]\n",
    "        ret_attrs[r_mask] = v[r_mask]/i[r_mask]\n",
    "\n",
    "        return ret_attrs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Instance of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[2.],\n",
       "         [1.]], requires_grad=True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = ckt.Input(vr)\n",
    "model = Solve(input=input)\n",
    "list(model.parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(),lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No inference therefore no testing!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mask():\n",
    "    masks = input.known_masks()\n",
    "    mask_list = []\n",
    "    for m in range(len(masks)):\n",
    "        mask_list.append(masks[m].to(torch.bool))\n",
    "    mask_tuple = tuple(mask_list)\n",
    "    return torch.cat(tensors=(mask_tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truth_vals():\n",
    "    truths = input.init_tensors()\n",
    "    truth_list = []\n",
    "    for m in range(len(truths)):\n",
    "        if(m==2):\n",
    "            #skip pots\n",
    "            continue\n",
    "        truth_list.append(truths[m])\n",
    "    truth_tuple = tuple(truth_list)\n",
    "    return torch.cat(tensors=(truth_tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [0.5000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [2.0000],\n",
       "        [1.0000]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_vals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 2.0000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_vals()[loss_mask()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 5.624999046325684\n",
      "epoch 361 loss = 4.50008487701416 finished early for loss change\n",
      "Done!\n",
      "pred tensor([[-0.5129],\n",
      "        [ 0.5129],\n",
      "        [ 2.0000],\n",
      "        [ 2.0000],\n",
      "        [-1.0000],\n",
      "        [ 1.0000]], grad_fn=<LinalgLstsqBackward0>)\n",
      "truth tensor([0.5000, 2.0000])\n",
      "attr [Parameter containing:\n",
      "tensor([[2.0000],\n",
      "        [3.9000]], requires_grad=True)]\n",
      "pred known tensor([ 0.5129, -1.0000], grad_fn=<IndexBackward0>)\n",
      "true vals known tensor([0.5000, 2.0000])\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "prev_loss = 0.1\n",
    "lt_prev_loss = 1000\n",
    "\n",
    "true_vals = truth_vals()\n",
    "\n",
    "knowns_mask = loss_mask()\n",
    "\n",
    "for t in range(epochs):\n",
    "\n",
    "    #set training mode\n",
    "    model.train()\n",
    "\n",
    "    pred = model()\n",
    "    loss = loss_fn(pred[knowns_mask], true_vals[knowns_mask])\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    loss.backward(retain_graph=False)\n",
    "\n",
    "    model.zero_known_grads()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    # analyze steps and loss\n",
    "    loss_change = abs(loss - prev_loss) / prev_loss\n",
    "    prev_loss = loss\n",
    "\n",
    "    if (t % (epochs/10)) == 0:\n",
    "        print(f'epoch {t} loss: {loss.item()}')\n",
    "        if loss > lt_prev_loss:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] /= 2\n",
    "        lt_prev_loss = loss\n",
    "\n",
    "    if (loss_change < 1e-30):\n",
    "        print(f'epoch {t} loss = {loss} finished early for loss change')\n",
    "        break\n",
    "\n",
    "    if loss < 1e-10:\n",
    "        print(f'epoch {t} loss = {loss} finished early for loss threshold')\n",
    "        break\n",
    "\n",
    "print(\"Done!\")\n",
    "print(f'pred {pred}')\n",
    "print(f'truth {true_vals[knowns_mask]}')\n",
    "print(f'attr {list(model.parameters())}')\n",
    "print(f'pred known {pred[knowns_mask]}')\n",
    "print(f'true vals known {true_vals[knowns_mask]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8932870626449585"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3217f10b4e7366dd1a6cbf73464f125221bf8686d6dfc23b58c931b1c5e4bd4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
