{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from circuits import Circuit,Kinds\n",
    "from learn import Trainer\n",
    "from models import Solver\n",
    "from models import State\n",
    "from data import Preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "torch.set_printoptions(precision=3, linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr = Circuit()\n",
    "vr.ring(Kinds.IVS,Kinds.R,100)\n",
    "vr.elements[0].attr = 1\n",
    "vr.elements[-1].i = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\terry\\OneDrive\\Documents\\GitHub\\side_circuit\\ml\\circuits.py:104: FutureWarning: incidence_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  M_scipy = nx.incidence_matrix(G=self.nx_graph(),oriented=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init params: Parameter containing:\n",
      "tensor([1.000e+00, 1.788e-01, 5.379e-02, 7.287e-01, 8.598e-01, 1.212e-01, 5.185e-01, 8.139e-01, 7.806e-01, 5.233e-01, 6.883e-01, 1.068e-01, 3.116e-01, 6.913e-01, 1.222e-01, 4.805e-01, 6.322e-01,\n",
      "        5.913e-01, 8.208e-01, 5.247e-02, 4.013e-03, 2.095e-01, 6.379e-01, 5.402e-01, 7.603e-01, 5.316e-02, 9.809e-02, 1.753e-01, 3.666e-01, 8.629e-01, 8.001e-01, 1.000e-12, 5.640e-01, 5.875e-01,\n",
      "        8.977e-01, 4.570e-01, 8.654e-01, 5.983e-01, 7.678e-01, 2.935e-01, 8.184e-01, 6.134e-01, 3.874e-01, 1.574e-01, 4.928e-01, 3.549e-01, 6.429e-01, 2.315e-02, 2.286e-01, 6.871e-01, 3.193e-01,\n",
      "        6.059e-01, 4.622e-01, 5.657e-01, 6.462e-01, 2.874e-01, 6.867e-01, 6.752e-01, 4.900e-01, 5.635e-01, 3.948e-01, 3.275e-01, 7.243e-01, 5.224e-01, 4.865e-01, 8.923e-01, 7.513e-01, 1.151e-02,\n",
      "        7.198e-01, 4.796e-01, 5.251e-01, 6.675e-01, 1.000e-12, 1.000e-12, 2.974e-01, 5.610e-01, 2.473e-01, 7.192e-01, 4.852e-01, 7.854e-01, 8.581e-01, 2.633e-01, 4.647e-01, 3.162e-01, 7.938e-01,\n",
      "        7.746e-01, 8.666e-01, 7.151e-01, 5.952e-01, 1.000e-12, 7.912e-01, 7.641e-01, 2.070e-01, 5.291e-01, 4.127e-01, 8.616e-01, 6.624e-01, 1.000e-12, 1.000e-12, 1.000e-12, 8.689e-01],\n",
      "       requires_grad=True)\n",
      "init loss: 0.11657842993736267\n",
      "Done! at 1000 passes, 0.1223401427268982 loss\n",
      "solution = tensor([[-0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 0.005],\n",
      "        [ 1.000],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.011],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [ 0.010],\n",
      "        [-0.010],\n",
      "        [ 0.990],\n",
      "        [ 0.980],\n",
      "        [ 0.970],\n",
      "        [ 0.960],\n",
      "        [ 0.950],\n",
      "        [ 0.940],\n",
      "        [ 0.930],\n",
      "        [ 0.920],\n",
      "        [ 0.910],\n",
      "        [ 0.900],\n",
      "        [ 0.890],\n",
      "        [ 0.880],\n",
      "        [ 0.870],\n",
      "        [ 0.860],\n",
      "        [ 0.850],\n",
      "        [ 0.840],\n",
      "        [ 0.830],\n",
      "        [ 0.820],\n",
      "        [ 0.810],\n",
      "        [ 0.800],\n",
      "        [ 0.790],\n",
      "        [ 0.780],\n",
      "        [ 0.770],\n",
      "        [ 0.760],\n",
      "        [ 0.750],\n",
      "        [ 0.740],\n",
      "        [ 0.730],\n",
      "        [ 0.721],\n",
      "        [ 0.710],\n",
      "        [ 0.700],\n",
      "        [ 0.690],\n",
      "        [ 0.680],\n",
      "        [ 0.670],\n",
      "        [ 0.660],\n",
      "        [ 0.650],\n",
      "        [ 0.640],\n",
      "        [ 0.630],\n",
      "        [ 0.620],\n",
      "        [ 0.610],\n",
      "        [ 0.600],\n",
      "        [ 0.590],\n",
      "        [ 0.580],\n",
      "        [ 0.570],\n",
      "        [ 0.560],\n",
      "        [ 0.550],\n",
      "        [ 0.540],\n",
      "        [ 0.530],\n",
      "        [ 0.520],\n",
      "        [ 0.510],\n",
      "        [ 0.500],\n",
      "        [ 0.490],\n",
      "        [ 0.480],\n",
      "        [ 0.470],\n",
      "        [ 0.460],\n",
      "        [ 0.450],\n",
      "        [ 0.440],\n",
      "        [ 0.430],\n",
      "        [ 0.420],\n",
      "        [ 0.410],\n",
      "        [ 0.400],\n",
      "        [ 0.390],\n",
      "        [ 0.380],\n",
      "        [ 0.371],\n",
      "        [ 0.361],\n",
      "        [ 0.350],\n",
      "        [ 0.340],\n",
      "        [ 0.330],\n",
      "        [ 0.320],\n",
      "        [ 0.310],\n",
      "        [ 0.300],\n",
      "        [ 0.290],\n",
      "        [ 0.280],\n",
      "        [ 0.270],\n",
      "        [ 0.260],\n",
      "        [ 0.250],\n",
      "        [ 0.240],\n",
      "        [ 0.231],\n",
      "        [ 0.221],\n",
      "        [ 0.211],\n",
      "        [ 0.200],\n",
      "        [ 0.190],\n",
      "        [ 0.180],\n",
      "        [ 0.170],\n",
      "        [ 0.160],\n",
      "        [ 0.151],\n",
      "        [ 0.140],\n",
      "        [ 0.130],\n",
      "        [ 0.120],\n",
      "        [ 0.110],\n",
      "        [ 0.100],\n",
      "        [ 0.090],\n",
      "        [ 0.080],\n",
      "        [ 0.070],\n",
      "        [ 0.060],\n",
      "        [ 0.050],\n",
      "        [ 0.040],\n",
      "        [ 0.030],\n",
      "        [ 0.020],\n",
      "        [ 0.010]], grad_fn=<LinalgSolveExBackward0>)\n",
      "attributes = Parameter containing:\n",
      "tensor([1.000, 1.862, 1.862, 1.862, 1.925, 1.862, 1.862, 1.880, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.886, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862,\n",
      "        1.862, 1.862, 1.929, 1.866, 1.862, 1.862, 1.862, 1.963, 1.862, 1.931, 1.862, 1.862, 1.862, 1.884, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862,\n",
      "        1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.958, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.924,\n",
      "        1.862, 1.862, 1.862, 1.862, 1.862, 1.932, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.862, 1.927, 1.862, 1.862, 1.862, 1.862, 1.935], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "prev_loss = 0.1\n",
    "\n",
    "input = Preprocess(vr)\n",
    "model = Solver(input=input, state=State.Solve)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),lr=0.1)\n",
    "trainer = Trainer(model,optimizer,nn.MSELoss())\n",
    "loss, _ = trainer.train()\n",
    "print(f'init params: {model.attr}')\n",
    "print(f'init loss: {loss.item()}')\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "while(epoch < num_epochs):\n",
    "    loss, _ = trainer.train()\n",
    "    if(loss < 1e-10):\n",
    "            break\n",
    "    epoch += 1\n",
    "    loss_change = abs(loss - prev_loss) / prev_loss\n",
    "    prev_loss = loss\n",
    "\n",
    "print(f'Done! at {epoch} passes, {loss.item()} loss')\n",
    "print(f'solution = {model()}')\n",
    "print(f\"attributes = {model.attr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3217f10b4e7366dd1a6cbf73464f125221bf8686d6dfc23b58c931b1c5e4bd4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
